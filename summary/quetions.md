<p align="right">参考 百面机器学习</p>
- 算法工程师: 算法研究应用到工作中, 从用户的角度思考问题
    - 发现问题的眼光
    - 解决问题的探索精神
    - 对问题究原竟委的执着追求

- 特征工程: 数据和特征决定了结果的上限
    - 特征归一化
    - 类别型特征
        - 序号编码: 大小关系
        - 独热编码
            - 稀疏向量
            - 特征选择
        - 二进制编码
    - 高维组合特征
        - 取值空间的乘积
            - 矩阵分解
    - 组合特征
        - 决策树
    - 文本表示模型
        - 词袋模型
            - TF-IDF
        - 主题模型: 从文本库中发现有代表性的主题,并且计算出每篇文章的主题分布
            - LDA: 文档-单词 -> 文档-主题到主题-单词
        - 词嵌入模型
            - Word2Vec
                - CBOW: 上下文出现的词语预测当前词的生成概率
                - Skip-gram: 当前词来预测上下文中各词的生成概率
    - 图像数据不足: 训练数据蕴含的信息 + 模型形成过程中的先验信息
        - 迁移学习
        - GAN
        - 图像处理
        - 上采样技术: 图像的特征空间内进行变换
        - 数据扩充
- 模型评估
    - 分类
        - Accuracy: 样本不平衡
        - Precision: TP/(TP + FP)
        - Recall: TP/(TP + FN)
        - P-R曲线 -> F1
        - ROC: 降低不同测试集带来的干扰, 阈值移动
            - TPR = TP / P
            - FPR = FP / N
        - AUC
    - 回归
        - RMSE: Outlier
            - 过滤噪声
            - Outlier产生机制建模
            - 更合适的指标
        - MAPE: 归一化
    - 余弦距离: 相对差异
        - 不满足三角不等式
    - A/B测试
        - 划分实验组和对照组
    - 模型验证
        - Holdout
        - 交叉检验
        - 自助法(Bootstrap): n次有放回的随机抽样
    - 超参数调优: Google Vizier
        - 网格搜索
        - 随机搜索
        - 贝叶斯优化: 充分利用之前的信息
    - 过拟合与欠拟合
        - 过拟合
            - 数据
            - 模型复杂度
            - 正则化
            - 集成学习
        - 欠拟合
            - 新特征
            - 模型复杂度
            - 减少正则化系数
- 经典模型
    - SVM
        - 支持向量: 分类结果只依赖支持向量
        - 核函数
        - SMO算法: 带松弛变量
    - LR
    - 决策树
        - 算法
            - ID3: 最大信息增益
            - C4.5: 最大信息增益比
            - CART: 最大基尼系数
        - 剪枝
            - 预剪枝: 简单, 欠拟合
                - 达到一定深度
                - 当前结点样本数量小于某个阈值
                - 每次分裂对测试集的准确度提升
            - 后剪枝: 泛化能力强, 时间开销大
                - Cost Complexity Pruning
- 降维
    - PCA
        -  最大化投影方差(协方差矩阵的最大特征值的特征向量)
        -  最小平方误差
     - LDA: 最大化类间距离和最小化类内距离
- 非监督学习
    - K-Means: 样本距离所属簇中心点的误差平方和, 复杂度小
        - 缺点
            - 初值和离群点的影响
            - 分布差距大
            - 离散分类
        - K-means++: 初始值改进
        - ISODATA: K值
    - GMM: 多个高斯分布函数的线性组合来对数据分布进行拟合
        - 权重 + 均值 + 方差: 
        - EM算法(局部最优解): 固定一个变量使整体函数变为凸优化函数, 求导得到最值, 然后利用最优参数更新被固定的参数
    - Self-Organizing Map: 两层的神经网络
    - 评估
        - 估计聚类趋势: 定义指标
        - 判定数据簇数
        - 测定聚类质量
- 概率图模型
    - 贝叶斯网络: 有向图
        - NB
    - 马尔可夫网络: 无向图
        - 最大熵
    - HMM
    - MEMM
    - CRF
    - 主题模型
        - pLSA
            - 主题分布 + 主题上的词分布: 常数
            - 最大化文本生成概率: EM算法
        - LDA
            - 参数服从一定分布的随机变量, 观察到样本信息后, 对先验分布进行修正, 得到后验分布
            - 推荐系统中的冷启动问题
- 优化算法
    - 损失函数
        - 0-1损失
            - Hinge损失: 相对紧的凸上界
        - 交叉熵
        - 平方损失
    - 凸优化
        - 凸: SVM, LR 
        - 非凸: 矩阵分解, DNN
    - 算法
        - 直接法: 正规方程
        - 迭代法
            - 一阶法
            - L-BFGS
            - 二阶法
        - SGD
            - 批量大小: 2的幂次
            - 训练数据: Shuffle
            - 学习速率: 惯性保持 + 环境感知
                - 山谷震荡
                - 鞍点
    - L1正则化与稀疏性: 带正则项和带约束条件等价
- 采样: 从特定的概率分布中抽取对应的样本点
    - 均匀分布随机数生成器
        - 线性同余法: 随机种子
    - 方法
        - 逆变换采样: 原函数
        - 参考分布
            - 拒绝采样: 选取合适的包络函数
            - 重要性采样: 函数期望
        - 马尔可夫蒙特卡洛采样法(MCMC): 高维空间
            - 构造马尔可夫链, 使得其状态转移序列收敛到目标分布
                - Metropolis-Hastings
                - 吉布斯采样法
            - 样本独立: 间隔若干个样本或多条马尔可夫链
    - 高斯分布采样
        - Box-Muller算法
    - 贝叶斯网络的采样
    - 不均衡样本集的重采样
        - 基于数据的方法
            - 过采样
                - 随机
                - SMOTE
            - 欠采样
                - 随机
                - Informed
        - 基于算法的方法
            - 单类学习
            - 异常检测 
- 神经网络
    - 表示异或
    - 激活函数
        - Sigmoid
        - RELU
        - Tanh
    - 训练技巧
        - 随机初始化
        - Dropout
        - 批量归一化
    - CNN
        - 稀疏交互: 局部特征
        - 参数共享: 平移不变性
        - ResNet: 残差拟合
    - RNN
        - 梯度消失: 初始化W为单位矩阵
        - LSTM/GRU
    - Seq2Seq
        - Beam Search
        - Attention
- 强化学习
    - 环境: 游戏本身的状态
    - 动作: 用户操作
    - 机器人: 程序
    - 回馈: 得分/输赢
- 集成学习
    - 分类
        - Bagging: 集体投票决策, 减少方差
            - 随机森林: 随机抽取属性子集
        - Boosting: 从错误中学习, 减少偏差
            - AdaBoost
                - 确定基分类器
                - 训练基分类器
                    - 初始化采样分布
                    - 确定基分类器错误率及权重
                    - 设置下一次采样
                - 合并基分类器: 加权投票
            - GBDT: 残差
                - 分布稠密
            - XGBoost
                - GBDT的工程实现
                - 显式加入正则项来控制模型的复杂度
                - 同时使用代价函数的一阶和二阶特征
                - 支持多种类型的基分类器
                - 支持对数据进行采样
                - 自动学习出缺失值的处理策略
    - 步骤
        - 找到误差相互独立的基分类器
            - 决策树
                - 样本权重整合到训练过程
                - 表达和泛化能力
                - 不稳定性
            - 神经网络
        - 训练基分类器
        - 合并基分类器的结果
- 总结
    - 适用问题
        - 分类
        - 回归
        - 标注
        - 生成
    - 模型
        - 判别
        - 生成
            - 非监督: EM算法
    - 学习策略
        - 极大似然估计/后验估计
        - 极小化损失函数
    - 学习算法
        - 凸二次规划
- 应用
    - 计算广告
        - 分类
            - 合约广告
            - 竞价广告
            - 程序化广告
        - 模块
            - 用户画像
            - 点击率预估
    - 游戏
        - "完美信息"游戏
        - "不完美信息"游戏
        - 电子竞技
        - 通用AI
    - 自动驾驶
        - 安全
        - 方便
        - 高效共享
        - 减少拥堵
    - 机器翻译
    - 人机交互